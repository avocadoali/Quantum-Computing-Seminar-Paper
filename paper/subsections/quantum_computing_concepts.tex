\section{Quantum computing concepts}
In this section, we will define common quantum computing concepts, relevant for understanding the HHL algorithm.

\subsection{Bra-ket Notation}
The \textit{bra-ket} notation is commonly used to represent quantum states, operators and measurements.
To begin with, a qubit can be represented by a 2d-vector $\vec v$ which can be written in its \textit{ket} form $\ket v$.
The most common \textit{kets} are the $0$ and $1$ \textit{kets}, which are written as $\ket 0$ and $\ket 1$ respectively.
These are the basis states that represent the 0 and 1 bit on a classical computer. 
As already mentionend, we can think of a \textit{ket} as a vector. 
In vector form $\ket 0$ and $\ket 1$ are the defined by these vectors as such

\begin{equation}
  \ket 0  = \begin{pmatrix}1\\0\end{pmatrix} 
\end{equation}

\begin{equation}
  \ket 1  = \begin{pmatrix}0\\1\end{pmatrix}
\end{equation}

Graphically we can think of these two qubits $\ket 0$ and $\ket 1$ as two orthonormal vectors pointing upwards and to the right, having the length of 1.

Multiple qubits can be combined to a quantum state often refered to as $\ket \Psi$, describing the state of a quantum computer. 
For example, if we have a quantum computer with 4 qubits which are all initialized to the 0 state, $\ket \Psi$ would look as such

\begin{equation}
    \ket \Psi = \ket 0 \otimes \ket 0 \otimes \ket 0 \otimes \ket 0 = \ket{0000}
\end{equation}
where $\otimes$ is the tensor product, which is often times simplified into one state.

The inner product of two vectors $\vec a$ and $\vec b$ is represented in braket notation as such 
\begin{equation}
    \braket{a | b}
\end{equation}
where $\bra a$ as the \textit{bra} and $\ket b$ is the \textit{ket}.
The \textit{bra} vector is defined as the complex conjugate of the \textit{ket} vector. 
For example
\begin{equation}
  \ket a=  \begin{pmatrix}1\\-i\end{pmatrix}  \Rightarrow \bra a = \begin{pmatrix}1 & i\end{pmatrix}
\end{equation}
Note that the vectors contain complex numbers.

\subsection{Superposition and Quantum Gate}
As we already know qubits of a quantum computer can be in states \textit{between} 0 and 1. 
These states are superpositions where a qubit is neither 0 nor 1.
Mathematically, superpositions can be represented by a linear combination of basis states. 
The most common superposition is created by the Hadamard gate, which puts a basis state into an equal superposition. 
Meaning, the probability of the qubit collapsing to either 0 or 1 is $\frac 1 2$.
The Hadamard gate $H$ looks likes this
\begin{equation}
    H = \frac{1}{\sqrt{2}} \begin{pmatrix}1 & 1\\ 1 & -1\end{pmatrix}  
\end{equation}

Note that a quantum gate is represented by a matrix.
That means, if we want to apply quantum gates on qubits, we calculate transformations of vectors by matrices. 
Lets apply the Hadamard gate $H$ to the basis state $\ket 0$
\begin{equation}
   \begin{split}
   H \ket 0 &=  \frac{1}{\sqrt{2}} \begin{pmatrix}1 & 1\\ 1 & -1\end{pmatrix} \begin{pmatrix}1\\0\end{pmatrix}   
    =  \frac{1}{\sqrt{2}} \begin{pmatrix}1\\1\end{pmatrix}   \\
    &=  \frac{1}{\sqrt{2}} (\ket 0 + \ket 1)  = \ket +
   \end{split}
\end{equation}
Graphically, the vector of the Hadamard state $\ket +$ lies exactly between the basis vectors $\ket 0$ and $\ket 1$.
That means the state has equal probability to collapse to the $\ket 0$ and $\ket 1$ state.


\subsection{Hermitian matrix}
A Hermitian matrix is a matrix, which is equal to its adjoint matrix. 
That means a matrix containing complex entries, is equal to itself after transposing and taking the complex conjugate of itself. 
Thus, a hermitian matrix $A^\dagger$ is defined as such
\begin{equation}
 A = \overline{A^T} \Leftrightarrow A^\dagger
\end{equation}
For example, the following matrix is Hermitian





\begin{equation}
\begin{split}
A &= \begin{bmatrix} 2 & 1-i \\ 1+i & 3 \\ \end{bmatrix} \\
\overline A &= \begin{bmatrix} 2 & 1+i \\ 1-i & 3 \\ \end{bmatrix}\\
\overline{A^T} &= \begin{bmatrix} 2 & 1-i \\ 1+i & 3 \\ \end{bmatrix} = A\\
\Rightarrow A &= \overline{A^T} = A^\dagger
\end{split}
\end{equation}

Hermitian matrices are important as we can easily encode them into quantum systems.
More details will follow in the subsection for types of encoding.

\subsection{Spectral Decomposition}
Let's say we have a Matrix $A$ that we can diagonalize. 
Then we can describe it by its spectrum which is a matrix with the eigenvalues in its diagonal
\begin{equation} 
\begin{split}
A &=  U D U^{\dagger} \\
&= \begin{pmatrix} U_1 & \dots & U_n \end{pmatrix} \begin{pmatrix} \lambda_1 & 0 & 0 \\  0 & \ddots & 0\\ 0 & 0& \lambda_n \\ \end{pmatrix} \begin{pmatrix} U^\dagger_1 \\ \vdots \\ U^\dagger_n \end{pmatrix}
\end{split}
\end{equation}
where $D$ is the diagonal matrix consisting of the eigenvalues and U consisting of eigenvectors of $A$.
With this, we can describe a matrix only by its eigenvectors and eigenvalues. 
Similarly, we can also determine the inverse $A^{-1}$ by simply inverting the eigenvalues as such

\begin{equation}
\begin{split}
 A^{-1} 
 &=  U^{\dagger} D^{-1} U\\
 &= \begin{pmatrix} U^\dagger_1 \\ \vdots \\ U^\dagger_n \end{pmatrix}
\begin{pmatrix} \lambda_1^{-1} & 0 & 0\\ 0 & \ddots & 0\\ 0 & 0& \lambda_n^{-1} \\ \end{pmatrix}
\begin{pmatrix} U_1 & \dots & U_n \end{pmatrix} 
\end{split}
\end{equation}


Classically calculating the inverse matrice by inverting its eigenvalues is comparably slow. 
Though in the quantum version, we will see, that this will play a big role in making our computation faster, as computing eigenvalues can by done efficiently by Quantum Phase Estimation (QPE).

\subsection{Types of Encoding}
Here we will discuss three common kinds of encodings namely, Hamiltonian encoding, Basis encoding and Amplitude encoding.

\subsubsection{Hamiltonian Encoding}
One type of Hamiltonian encoding is to encode a matrix into a unitary gate which can be implemented into logical quantum gate. 
That means we can encode a matrix $A$ into our quantum system.
For example, a possible unitary gate of the matrix $A$ is
\begin{equation}
    U = e^{iAt}
\end{equation}
if $A$ is a Hermitian matrix.

\subsubsection{Basis Encoding}
Basis encoding converts classical numbers into quantum states.
By using the binary representation of a number, we can directly write it into our quantum state. 
\begin{equation}
    x \rightarrow \ket {x}
\end{equation}
where $x$ is a binary number.
Let's say we have $x=3$ as a decimal number which can be represented as a binary number as $x_b = 11$.
Then we can encode it in our quantum state as such
\begin{equation}
    x=3 \xrightarrow[]{binary} x_b = 11 \xrightarrow[]{quantum\  state} \ket{x_b} = \ket{11}
\end{equation}

\subsubsection{Amplitude Encoding}
Amplitude encoding encodes a vector $\vec x$ into a quantum state $\ket x$. 
We assume, that the vector $\vec x$ is normalized. 
Then we can use the elements of the vector $\vec x$ as coefficients of the states $\ket 0 \dots \ket {N-1}$ as such
\begin{equation}
    \vec{x} = \begin{pmatrix} x_0\\ \vdots \\ x_{N-1} \end{pmatrix} 
    \Leftrightarrow  
     \ket x = \sum_{i=0}^{N-1} x_i \ket i
\end{equation}

\subsection{Kronecker Delta}
The Kronecker delta $\delta_{ij}$ is often used to simplify calculations with inner products $\braket{\psi | \phi}$.
Basically, $\psi$ and $\phi$ can be handled like normal vectors. 
The inner product calculates the angle between vectors which means that, for two orthogonal kets, the inner product is $0$ as such
\begin{equation}
\braket{\psi|\phi} = 0 \text{, if } \psi \perp \phi\\
\end{equation}

Let's say we have an orthonormal basis $\ket{E_i}$, meaning all basis vectors are orthonormal to each other.
Then, we have the following relation
\begin{equation}
\begin{split}
\braket{E_i|E_i} &= 1\\
\braket{E_i|E_j} &= 0, \ i\neq j
\end{split}
\end{equation}

We can see that if the indices are the same, which means the vectors are pointing in the same direction, the inner product is $1$.
If they are orthogonal to each other, meaning every other vector is an orthonormal basis, then the inner product is $0$.
This can be summarized in the Kronecker delta
\begin{equation}
    \delta_{ij} = \braket{E_i|E_j} = \begin{cases} 1 & \text{if } i=j\\ 0 & \text{if } i \neq j
\end{cases}
\end{equation}

This can be quite useful in calculations with orthonormal bases.
When calculating inner products of an orthonormal basis, whilst the indices are not equal, terms are multiplied by $0$ and will be cancle out, simplifying the equation.

\subsection{Etangled states}
Entangled states can not be represented by a tensor product of individual states. 
Entangled states are defined as such
\begin{equation}
    \ket{\Phi} \neq \ket{\phi} \ket{\psi}
\end{equation}
As an example here we have a state $\ket{\Phi_1}$ which is not entangled, as we can represent it by two other states
\begin{equation}
\begin{split}
\ket{\Phi_1} &= \frac{1}{\sqrt{2}} ( \ket{10} + \ket{11}) \\ 
&= \ket{1}\otimes \frac{1}{\sqrt{2}} ( \ket{0} + \ket{1})\\ 
&= \ket{1} \ket{+}
\end{split}
\end{equation}
where $\ket +$ is the Hadmard  state $H \ket{0}$.
On the other hand, the following state $\Phi_2$ is entangled 
\begin{equation}
\begin{split}
\ket{\Phi_2} &= \frac{1}{\sqrt{2}} ( \ket{00} + \ket{11}) \\
&\neq \ket{\alpha}\ket{\beta}
\end{split}
\end{equation}
as it cannot be represented by other states.
